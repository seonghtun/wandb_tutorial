{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BMovyigQE0fv"},"outputs":[],"source":["!pip install --quiet optuna"]},{"cell_type":"code","source":["import os\n","\n","import optuna\n","from optuna.trial import TrialState\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data\n","from torchvision import datasets\n","from torchvision import transforms"],"metadata":{"id":"fYVQYgS_E4LN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DEVICE = torch.device(\"cuda\")\n","BATCHSIZE = 128\n","CLASSES = 10\n","DIR = os.getcwd()\n","EPOCHS = 10\n","N_TRAIN_EXAMPLES = BATCHSIZE * 30\n","N_VALID_EXAMPLES = BATCHSIZE * 10"],"metadata":{"id":"GVFGwCxrE8eC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def define_model(trial):\n","    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n","    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n","    layers = []\n","\n","    in_features = 28 * 28\n","    for i in range(n_layers):\n","        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n","        layers.append(nn.Linear(in_features, out_features))\n","        layers.append(nn.ReLU())\n","        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n","        layers.append(nn.Dropout(p))\n","\n","        in_features = out_features\n","    layers.append(nn.Linear(in_features, CLASSES))\n","    layers.append(nn.LogSoftmax(dim=1))\n","\n","    return nn.Sequential(*layers)"],"metadata":{"id":"o6IYniULFBBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_mnist():\n","    # Load FashionMNIST dataset.\n","    train_loader = torch.utils.data.DataLoader(\n","        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n","        batch_size=BATCHSIZE,\n","        shuffle=True,\n","    )\n","    valid_loader = torch.utils.data.DataLoader(\n","        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n","        batch_size=BATCHSIZE,\n","        shuffle=True,\n","    )\n","\n","    return train_loader, valid_loader"],"metadata":{"id":"g2j6S_FWFDLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","\n","    # Generate the model.\n","    model = define_model(trial).to(DEVICE)\n","\n","    # Generate the optimizers.\n","    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n","    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n","\n","    # Get the FashionMNIST dataset.\n","    train_loader, valid_loader = get_mnist()\n","\n","    # Training of the model.\n","    for epoch in range(EPOCHS):\n","        model.train()\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            # Limiting training data for faster epochs.\n","            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n","                break\n","\n","            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = F.nll_loss(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Validation of the model.\n","        model.eval()\n","        correct = 0\n","        with torch.no_grad():\n","            for batch_idx, (data, target) in enumerate(valid_loader):\n","                # Limiting validation data.\n","                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n","                    break\n","                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n","                output = model(data)\n","                # Get the index of the max log-probability.\n","                pred = output.argmax(dim=1, keepdim=True)\n","                correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n","\n","        trial.report(accuracy, epoch)\n","\n","        # Handle pruning based on the intermediate value.\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","    return accuracy"],"metadata":{"id":"27mKuV3ZFEs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    study = optuna.create_study(direction=\"maximize\")\n","    study.optimize(objective, n_trials=100, timeout=600)\n","\n","    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","    print(\"Study statistics: \")\n","    print(\"  Number of finished trials: \", len(study.trials))\n","    print(\"  Number of pruned trials: \", len(pruned_trials))\n","    print(\"  Number of complete trials: \", len(complete_trials))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: \", trial.value)\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"wKsP5aBsFGy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zOGWmqmjFJtW"},"execution_count":null,"outputs":[]}]}