{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"E3EflyOe_A-E"},"outputs":[],"source":["!pip install wandb -qU\n","!pip install --quiet optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MSA95cy_Pbx"},"outputs":[],"source":["import wandb\n","import os\n","import optuna\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data\n","from torchvision import datasets\n","from torchvision import transforms\n","\n","wandb.login()\n","\n","# wandb might cause an error without this.\n","os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n","\n","DEVICE = torch.device(\"cuda\")\n","BATCHSIZE = 128\n","CLASSES = 10\n","DIR = os.getcwd()\n","EPOCHS = 100\n","LOG_INTERVAL = 10\n","N_TRAIN_EXAMPLES = BATCHSIZE * 30\n","N_VALID_EXAMPLES = BATCHSIZE * 10\n","STUDY_NAME = \"pytorch-optimization\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Xt7EMDd_a6V"},"outputs":[],"source":["def train(optimizer, model, train_loader):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Limiting training data for faster epochs.\n","        if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n","            break\n","\n","        data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSUnm4RK_fAS"},"outputs":[],"source":["def validate(model, valid_loader):\n","    # Validation of the model.\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(valid_loader):\n","            # Limiting validation data.\n","            if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n","                break\n","            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n","            output = model(data)\n","            # Get the index of the max log-probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n","\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aonZQhTD_jnu"},"outputs":[],"source":["def define_model(trial):\n","    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n","    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n","    layers = []\n","\n","    in_features = 28 * 28\n","\n","    for i in range(n_layers):\n","        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n","        layers.append(nn.Linear(in_features, out_features))\n","        layers.append(nn.ReLU())\n","        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n","        layers.append(nn.Dropout(p))\n","\n","        in_features = out_features\n","    layers.append(nn.Linear(in_features, CLASSES))\n","    layers.append(nn.LogSoftmax(dim=1))\n","\n","    return nn.Sequential(*layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gI05y-eB_lYm"},"outputs":[],"source":["# Get the data loaders of FashionMNIST dataset.\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.FashionMNIST(\n","        DIR, train=True, download=True, transform=transforms.ToTensor()\n","    ),\n","    batch_size=BATCHSIZE,\n","    shuffle=True,\n",")\n","valid_loader = torch.utils.data.DataLoader(\n","    datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n","    batch_size=BATCHSIZE,\n","    shuffle=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HE86ocV0qaz4"},"outputs":[],"source":["def objective(trial):\n","\n","    # Generate the model.\n","    model = define_model(trial).to(DEVICE)\n","\n","    # Generate the optimizers.\n","    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"RMSprop\", \"SGD\"])\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n","    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n","\n","    # init tracking experiment.\n","    # hyper-parameters, trial id are stored.\n","\n","    # Training of the model.\n","    for epoch in range(EPOCHS):\n","\n","        train(optimizer, model, train_loader)\n","        val_accuracy = validate(model, valid_loader)\n","\n","    return val_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edrDU8OX_uSR"},"outputs":[],"source":["def objective(trial):\n","\n","    # Generate the model.\n","    model = define_model(trial).to(DEVICE)\n","\n","    # Generate the optimizers.\n","    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"RMSprop\", \"SGD\"])\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n","    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n","\n","    # init tracking experiment.\n","    # hyper-parameters, trial id are stored.\n","    config = dict(trial.params)\n","    config[\"trial.number\"] = trial.number\n","    wandb.init(\n","        project=\"optuna\",\n","        # entity=\"nzw0301\",  # NOTE: this entity depends on your wandb account.\n","        config=config,\n","        # group=STUDY_NAME,\n","        reinit=True,\n","    )\n","\n","    # Training of the model.\n","    for epoch in range(EPOCHS):\n","\n","        train(optimizer, model, train_loader)\n","        val_accuracy = validate(model, valid_loader)\n","        trial.report(val_accuracy, epoch)\n","\n","        # report validation accuracy to wandb\n","        wandb.log(data={\"validation accuracy\": val_accuracy}, step=epoch)\n","\n","        # Handle pruning based on the intermediate value.\n","        if trial.should_prune():\n","            wandb.run.summary[\"state\"] = \"pruned\"\n","            wandb.finish(quiet=True)\n","            raise optuna.exceptions.TrialPruned()\n","\n","    # report the final validation accuracy to wandb\n","    wandb.run.summary[\"final accuracy\"] = val_accuracy\n","    wandb.run.summary[\"state\"] = \"complated\"\n","    wandb.finish(quiet=True)\n","\n","    return val_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOeyCr2__6k0"},"outputs":[],"source":["study = optuna.create_study(\n","    direction=\"maximize\",\n","    study_name=STUDY_NAME,\n","    pruner=optuna.pruners.MedianPruner(),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R1wZ2NYN__eF"},"outputs":[],"source":["study.optimize(objective, n_trials=100, timeout=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ksJB3KYABIL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}