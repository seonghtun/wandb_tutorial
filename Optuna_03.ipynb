{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ak6_IHWFF8I8"},"outputs":[],"source":["!pip install --quiet optuna"]},{"cell_type":"code","source":["import numpy as np\n","import optuna\n","\n","import sklearn.datasets\n","import sklearn.metrics\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb"],"metadata":{"id":"PuVKRPQhF_kh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","    (data, target) = sklearn.datasets.load_breast_cancer(return_X_y=True)\n","    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n","    dtrain = xgb.DMatrix(train_x, label=train_y)\n","    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n","\n","    param = {\n","        \"verbosity\": 0,\n","        \"objective\": \"binary:logistic\",\n","        # use exact for small dataset.\n","        \"tree_method\": \"exact\",\n","        # defines booster, gblinear for linear functions.\n","        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n","        # L2 regularization weight.\n","        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n","        # L1 regularization weight.\n","        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n","        # sampling ratio for training data.\n","        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n","        # sampling according to each tree.\n","        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n","    }\n","\n","    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n","        # maximum depth of the tree, signifies complexity of the tree.\n","        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n","        # minimum child weight, larger the term more conservative the tree.\n","        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n","        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n","        # defines how selective algorithm is.\n","        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n","        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n","\n","    if param[\"booster\"] == \"dart\":\n","        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n","        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n","        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n","        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n","\n","    bst = xgb.train(param, dtrain)\n","    preds = bst.predict(dvalid)\n","    pred_labels = np.rint(preds)\n","    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n","    return accuracy"],"metadata":{"id":"XKEJudCRGCXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    study = optuna.create_study(direction=\"maximize\")\n","    study.optimize(objective, n_trials=100, timeout=600)\n","\n","    print(\"Number of finished trials: \", len(study.trials))\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"PUwR_jVzGGj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"koRJAXHZGInN"},"execution_count":null,"outputs":[]}]}